---
output: pdf_document
fontsize: 12pt
geometry: margin=3cm
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```


Extract from:  
Bradley Efron and Trevor Hastie  
*Computer Age Statistical Inference: Algorithms, Evidence, and Data Science  Cambridge University Press, 2016  
https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf*

&nbsp;
&nbsp;
&nbsp;
  
  
  

Modern Bayesian practice uses various strategies to construct an appropriate “prior” $g(\mu)$ in the absence of prior experience, leaving many statisticians unconvinced by the resulting Bayesian inferences. Our second example illustrates the difficulty.

**Table 3.1** *Scores from two tests taken by 22 students, mechanics and vectors.*

```{r pressure, echo=FALSE}
mechanics <- c(7,44,49,59,34,46,0,32,49,52,44,36,42,5,22,18,41,48,31,42,46,63)
vectors <- c(51,69,41,71,42,40,40,45,57,64,61,59,60,30,58,51,63,38,42,69,49,63)
tbl <- cbind(mechanics,vectors)
kable(tbl, format = "latex")

```


Table 3.1 shows the scores on two tests, mechanics and vectors, achieved by $n=22$ students. The sample correlation coefficient between the two scores is $\widehat{\theta}=0.498$,
$$\widehat{\theta }=\sum_{i=1}^{22}(m_{i}-\overline{m})(v_{i}-\overline{v})/[\sum_{i=1}^{22}(m_{i}-\overline{m})^{2}\sum_{i=1}^{22}(v_{i}-\overline{v})^{2}]^{1/2}$$
with $m$ and $v$ short for mechanics and vectors, $\overline{m}$ and $\overline{v}$ their averages.






